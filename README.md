# vPIC Database Pipeline

A production-ready pipeline for downloading, processing, and optimizing the NHTSA vPIC (Vehicle Product Information Catalog) database for VIN decoding applications.

## ğŸš€ Quick Start

```bash
# Clone and setup
git clone <repository-url>
cd vpic-pipeline

# Run complete pipeline (downloads latest vPIC data and creates optimized database)
make sqlite-pipeline

# Find your optimized databases in temp/compressed/
ls -lh temp/compressed/
```

## ğŸ“‹ Overview

This pipeline transforms the massive NHTSA vPIC database into optimized, compressed formats suitable for production VIN decoding applications:

- **Download**: Latest vPIC database from NHTSA (~180MB ZIP, ~1.1GB uncompressed)
- **Process**: Restore SQL Server backup and migrate to SQLite 
- **Optimize**: Remove unnecessary tables and data for VIN decoding (336MB â†’ 63MB)
- **Compress**: Multiple compression formats (63MB â†’ 12MB with xz)

## ğŸ¯ Output Results

| Database Type | Uncompressed | gzip | bzip2 | xz | zstd |
|---------------|--------------|------|-------|----|----- |
| **Full** | 336MB | 92MB | 68MB | - | - |
| **Lite** (optimized) | 63MB | 20MB | 17MB | **12MB** | 15MB |

The **lite database** contains only essential tables for VIN decoding while maintaining 100% decoding accuracy.

## ğŸ—ï¸ Architecture

```
vPIC API â†’ SQL Server (Docker) â†’ SQLite â†’ Optimize â†’ Compress â†’ Production DB
```

### Key Components

- **Docker**: SQL Server container for .bak file restoration
- **Python**: Migration engine with type mapping and validation
- **SQLite**: Target database optimized for read-heavy VIN decoding
- **Bash Scripts**: Orchestration and optimization pipeline

## ğŸ“ Project Structure

```
vpic-pipeline/
â”œâ”€â”€ Makefile              # Main automation targets
â”œâ”€â”€ docker-compose.yml    # SQL Server & PostgreSQL containers  
â”œâ”€â”€ .env.example          # Environment configuration template
â”œâ”€â”€ scripts/              # Pipeline scripts
â”‚   â”œâ”€â”€ 01-download.sh    # Download latest vPIC data
â”‚   â”œâ”€â”€ 02-restore.sh     # Restore SQL Server backup
â”‚   â”œâ”€â”€ 03-verify.sh      # Verify database restoration
â”‚   â”œâ”€â”€ 04-optimize.sh    # Remove unnecessary tables/data
â”‚   â””â”€â”€ 05-compress.sh    # Compress optimized database
â”œâ”€â”€ src/                  # Python migration code
â”‚   â”œâ”€â”€ migrate.py        # Main migration orchestrator
â”‚   â”œâ”€â”€ database.py       # Database connection handlers
â”‚   â””â”€â”€ settings.py       # Configuration and type mappings
â””â”€â”€ temp/                 # Working directory (ignored by git)
    â”œâ”€â”€ vpic.db           # Full SQLite database
    â”œâ”€â”€ vpic.lite.db      # Optimized database
    â””â”€â”€ compressed/       # Final compressed outputs
```

## ğŸ› ï¸ Installation

### Prerequisites

- **Docker** and **Docker Compose**
- **Python 3.8+**
- **Make**
- Standard Unix tools: `curl`, `unzip`, `gzip`, `bzip2`, `xz`, `sqlite3`

### Setup

```bash
# 1. Clone repository
git clone <repository-url>
cd vpic-pipeline

# 2. Copy environment template
cp .env.example .env

# 3. Install Python dependencies
make setup

# 4. Run complete pipeline
make sqlite-pipeline
```

## ğŸ® Usage

### Full Pipeline (Recommended)

```bash
# Complete pipeline: download â†’ restore â†’ migrate â†’ optimize â†’ compress
make sqlite-pipeline
```

### Individual Steps

```bash
# Start containers
make start-containers

# Download latest vPIC data  
make download

# Restore to SQL Server
make restore

# Migrate to SQLite
make migrate-sqlite

# Optimize for VIN decoding
make optimize

# Compress database
make compress

# Clean up
make clean
```

### Database Outputs

After running the pipeline, you'll find:

```bash
temp/
â”œâ”€â”€ vpic.db                                    # Full database (336MB)
â”œâ”€â”€ vpic.lite.db                               # Optimized database (63MB)  
â””â”€â”€ compressed/
    â”œâ”€â”€ vpic_lite_YYYYMMDD.db.gz              # 20MB - Most compatible
    â”œâ”€â”€ vpic_lite_YYYYMMDD.db.bz2             # 17MB - Good balance
    â”œâ”€â”€ vpic_lite_YYYYMMDD.db.xz              # 12MB - Best compression
    â”œâ”€â”€ vpic_lite_YYYYMMDD.db.zst             # 15MB - Fastest decompression
    â”œâ”€â”€ vpic_lite_YYYYMMDD_checksums.sha256   # Integrity verification
    â””â”€â”€ vpic_lite_YYYYMMDD_info.json          # Release metadata
```

## âš™ï¸ Configuration

### Environment Variables

Copy `.env.example` to `.env` and customize:

```bash
# Database Passwords
MSSQL_SA_PASSWORD=DevPassword123#
POSTGRES_PASSWORD=postgres

# Container Names  
SQL_CONTAINER=vpic-sql
PG_CONTAINER=vpic-postgres

# Directories
TEMP_DATA_DIR=temp

# Connection Settings
CONNECTION_TIMEOUT=30
```

### Optimization Settings

The optimization process keeps only essential tables for VIN decoding:

- **Core Tables**: Make, Model, Pattern, Element, VinSchema, Wmi
- **Plant Info**: Plant location and manufacturing data
- **Vehicle Specs**: Body style, engine, fuel type, drivetrain
- **Removed**: Safety features, specialized vehicles, detailed technical specs
